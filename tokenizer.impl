
template<class TokenIdT, class ModeT>
Tokenizer<TokenIdT, ModeT>::Tokenizer() {
	
}

template<class TokenIdT, class ModeT>
Tokenizer<TokenIdT, ModeT>::~Tokenizer() {
	
}

template<class TokenIdT, class ModeT>
TokenIdT Tokenizer<TokenIdT, ModeT>::getTokenId_(const std::string &_token) {
	typename hashtable<std::string, TokenIdT>::iterator it = m_tokens.find(_token);
	if (it != m_tokens.end())
		return it->second;
	
	TokenIdT newid = m_tokens.size();
	m_tokens[_token] = newid;

	return newid;
}

template<class TokenIdT, class ModeT>
TokenIdT Tokenizer<TokenIdT, ModeT>::getTokenIdConst_(const std::string &_token) const {
	
	typename hashtable<std::string, TokenIdT>::const_iterator it = m_tokens.find(_token);
	if (it != m_tokens.end())
		return it->second;
	return 0;
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::splitByDelims_(const std::string &_text, std::vector<std::string> &_words) const  {
	
	boost::split(_words, _text, boost::is_any_of("., ;:	-(){}\"\'<>\n"));
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::tokenizeText_(const std::string &_text, TextRepr &_words, Type2Type<ByPrefixes>) {
	tokenizeTextPrefixes_(_text, _words);
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::tokenizeText_(const std::string &_text, TextRepr &_words, Type2Type<ByWords>) {
	
	std::string text (_text);
	toLowerUtf8(text);
	fix_utf8_string(text);
	
	
	std::vector<std::string> words;
	splitByDelims_(text, words);
	
	for (int i = 0; i<words.size(); i++)
		if (words[i].size() != 0) {
				_words.push_back(getTokenId_(words[i]));
		}
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::tokenizeText(const std::string &_text, TextRepr &_words) {
	
	
	tokenizeText_(_text, _words, Type2Type<ModeT>());
	
/*	if (m_by_pref) {
		tokenizeTextPrefixes(_text, _words);
		return;
	}
	
	std::string text (_text);
	toLowerUtf8(text);
	fix_utf8_string(text);
	
	
	std::vector<std::string> words;
	splitByDelims(text, words);
	
	for (int i = 0; i<words.size(); i++)
		if (words[i].size() != 0) {
				_words.push_back(getTokenId(words[i]));
		}*/
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::tokenizeTextConst(const std::string &_text, TextRepr &_words) const {
	
	
	std::string text (_text);
	toLowerUtf8(text);
	fix_utf8_string(text);
	
	std::vector<std::string> words;
	splitByDelims_(text, words);
	
	for (int i = 0; i<words.size(); i++)
		if (words[i].size() != 0) {
			TokenIdT id = getTokenIdConst_(words[i]);
			if (id != 0)
				_words.push_back(id);
		}
	
}

template<class TokenIdT, class ModeT>
void Tokenizer<TokenIdT, ModeT>::tokenizeTextPrefixes_(const std::string &_str_query, TextRepr &_text) {
	
	std::string text (_str_query);
	toLowerUtf8(text);
	fix_utf8_string(text);
	
	std::vector<std::string> words;
	splitByDelims_(text, words);
	
	for (int i = 0; i<words.size(); i++)
		if (words[i].size() != 0) {
			
			std::vector<std::string> prefixes;
			getPrefixesUtf8(words[i], prefixes);
			
			for (int j = 0; j<prefixes.size(); j++)
				_text.push_back(getTokenId_(prefixes[j]));
		}
}
/*
void Tokenizer::tokenizeDoc(uint64_t _id, const std::string &_text, Doc &_doc) {
	
	//std::string title(_title);
	std::string text(_text);
		
	tokenizeText(text, _doc.text);
	//tokenizeText(title, _doc.title);
	_doc.id = _id;
}*/
